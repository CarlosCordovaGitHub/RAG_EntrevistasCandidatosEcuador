{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\carlo\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('unified_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrevistas = df[['id', 'candidato_raw', 'entrevista_raw', 'entrevista_pre']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del DataFrame de entrevistas:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              56 non-null     object\n",
      " 1   candidato_raw   56 non-null     object\n",
      " 2   entrevista_raw  56 non-null     object\n",
      " 3   entrevista_pre  56 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "Primeras filas:\n",
      "       id candidato_raw                                     entrevista_raw  \\\n",
      "0  WGE001  Wilson Gomez  Yo vengo trabajando para muchos presidentes he...   \n",
      "1  WGE002  Wilson Gomez  Buenos días nos encontramos con Wilson Gómez c...   \n",
      "2  WGE003  Wilson Gomez  un gran abrazo para la inmensa audiencia de ra...   \n",
      "3  WGP004  Wilson Gomez  Parte 1: Diagnóstico de la Situación Actual La...   \n",
      "4  WGP005  Wilson Gomez  Parte 1: Extracción de petróleo en Ecuador Dia...   \n",
      "\n",
      "                                      entrevista_pre  \n",
      "0  veng trabaj president oportun serv voluntari e...  \n",
      "1  buen dias encontr wilson gomez candidat presid...  \n",
      "2  gran abraz inmens audienci radi moren ecuador ...  \n",
      "3  part diagnost situacion actual agricultur pesc...  \n",
      "4  part extraccion petrole ecuador diagnost situa...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Información del DataFrame de entrevistas:\")\n",
    "print(df_entrevistas.info())\n",
    "print(\"\\nPrimeras filas:\")\n",
    "print(df_entrevistas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Limpieza básica del texto\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Eliminar caracteres especiales manteniendo puntuación importante\n",
    "    text = re.sub(r'[^\\w\\s,.!?¿¡]', '', text)\n",
    "    \n",
    "    # Normalizar espacios\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=512):\n",
    "    \"\"\"Divide el texto en chunks más pequeños\"\"\"\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "            \n",
    "        if len(current_chunk) + len(sentence) < max_length:\n",
    "            current_chunk += sentence + \". \"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \". \"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "        \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando entrevistas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49efd48b873d4fc3bfa6b9a4eb041fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks generados: 56\n"
     ]
    }
   ],
   "source": [
    "documents = []        # Para los embeddings (texto limpio)\n",
    "original_texts = []   # Para mostrar (texto original)\n",
    "metadata_list = []\n",
    "ids = []\n",
    "\n",
    "\n",
    "print(\"Procesando entrevistas...\")\n",
    "for idx, row in tqdm(df_entrevistas.iterrows(), total=len(df_entrevistas)):\n",
    "    # Usar entrevista_pre para embeddings\n",
    "    texto_limpio = clean_text(row['entrevista_pre'])\n",
    "    # Guardar entrevista_raw para visualización\n",
    "    texto_original = row['entrevista_raw']\n",
    "    \n",
    "    if texto_limpio:  # Solo procesar si hay texto\n",
    "        # Dividir en chunks el texto limpio\n",
    "        chunks = chunk_text(texto_limpio)\n",
    "        # Dividir en chunks el texto original (misma longitud)\n",
    "        chunks_originales = chunk_text(texto_original)\n",
    "        \n",
    "        # Almacenar cada chunk con sus metadatos\n",
    "        for chunk_idx, (chunk, chunk_original) in enumerate(zip(chunks, chunks_originales)):\n",
    "            documents.append(chunk)  # Para embeddings\n",
    "            original_texts.append(chunk_original)  # Para mostrar\n",
    "            metadata_list.append({\n",
    "                \"id_original\": str(row[\"id\"]),\n",
    "                \"candidato\": row[\"candidato_raw\"],\n",
    "                \"chunk_id\": chunk_idx,\n",
    "                \"texto_original\": chunk_original  # Guardamos el texto original en metadata\n",
    "            })\n",
    "            ids.append(f\"entrevista_{row['id']}_chunk_{chunk_idx}\")\n",
    "\n",
    "\n",
    "print(f\"Total de chunks generados: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7e3f5f4e7e4b899428f187a967a08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Generando embeddings...\")\n",
    "embeddings = model.encode(documents, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"entrevistas_candidatos\"\n",
    "collection = chroma_client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almacenando en ChromaDB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820a84bf32b34ede85f953307b9fe3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almacenamiento completado. Total de chunks: 56\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "print(\"Almacenando en ChromaDB...\")\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    end_idx = min(i + batch_size, len(documents))\n",
    "    collection.add(\n",
    "        documents=documents[i:end_idx],\n",
    "        embeddings=embeddings[i:end_idx].tolist(),\n",
    "        metadatas=metadata_list[i:end_idx],\n",
    "        ids=ids[i:end_idx]\n",
    "    )\n",
    "\n",
    "print(f\"Almacenamiento completado. Total de chunks: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retrieval(query_text, n_results=3):\n",
    "    \"\"\"Prueba la recuperación de documentos mostrando el texto original\"\"\"\n",
    "    print(f\"\\nConsulta: {query_text}\")\n",
    "    \n",
    "    # Generar embedding para la consulta\n",
    "    query_embedding = model.encode(query_text)\n",
    "    \n",
    "    # Realizar búsqueda\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\nResultados:\")\n",
    "    for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):\n",
    "        print(f\"\\nCandidato: {metadata['candidato']}\")\n",
    "        print(f\"ID Original: {metadata['id_original']}\")\n",
    "        print(f\"Texto original de la entrevista:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"{metadata['texto_original']}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"¿Qué proponen los candidatos sobre la seguridad?\",\n",
    "    \"¿Cuáles son sus planes económicos principales?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consulta: ¿Qué proponen los candidatos sobre la seguridad?\n",
      "\n",
      "Resultados:\n",
      "\n",
      "Candidato: Ivan Saquicela\n",
      "ID Original: IS1\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "Ahora una nueva entrevista dentro de la Especial Elecciones 2025 Los Presidenciables. Iván Saquicela conforma el binomio de democracia así, junto a María Luisa Cuello para participar en los comicios. Saquicela renunció hace cinco meses a la Corte Nacional de Justicia, organismo que también presidió. Fue consejal de cuenca entre 2013 y 2007, luego fue fiscal hasta el año 2015. Además, es docente, universitario, abogado y criminólogo. En el servicio de rentas internas, suma el pago de 46.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Candidato: Jorge Escala\n",
      "ID Original: JE3\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "y seguimos con el especial elecciones 2025 los presidenciables hoy vino a contacto directo Jorge escala quien mañana va a cumplir 55 años y encabeza el Binomio de unidad popular binomio que lo completa pacha Terán toda su carrera política ha sido en el mismo partido que antes se llamaba mpd el movimiento popular democrático y es unidad popular desde hace algunos años desde 1993 escala ha sido docente y sindic lista fue presidente de la une asambleísta Constituyente estuvo en la comisión legislativa y de fiscalización recordada como congresillo tuvo también una curul en la asamblea de 2009 en la superintendencia de compañías consta como accionista del centro para el desarrollo de la educación investigación y tecnología y pagó un impuesto a la renta de 2019 a 2020 de 1100 Aproximadamente en estos 2 años y no registra impuesto a la salida de Divisas entre sus propuestas de campaña están acabar con el subsidio eléctrico a grandes mineras y a empresas también de de grandes dimensiones eh consiguiendo según el candidato 150 millones de dólares con esa medida también propone auditar la última década de los funcionarios judiciales Elevar el salario mínimo al costo de la canasta básica que se ubicó en el mes de noviembre en 804 también propone reducir el IVA al 10% y dejar de pagar la deuda externa Durante los 4 años de su gobierno hoy se encuentra aquí en los estudios de Guayaquil y le damos los buenos días a Jorge escala Gracias por acompañarnos cómo está alenis Muy buenos días Gracias por la oportunidad un saludo a la audiencia de contacto directo quería preguntarle Cuántos colaboradores tiene usted en el centro para el desarrollo de la educación investigación y tecnología dos dos y y ese centro tiene la solidez económica para casi duplicar el salario de sus trabajadores dos directivos y dos secretarios sí está manera que es una institución que le brinda capacitación desarrollo profesional que debe garantizarlo al estado en mi gobierno va a ser política pública va a ser una inversión la mejor manera de brindar calidad de la educación es eh profesionalizando a los docentes y usted les podría duplicar el salario a esos dos colaboradores eh Por supuesto en la medida de que tengamos nosotros ingresos para cubrir esas necesidades en la medida también de que se le demos incentivo porque a estas pequeñas pequeños emprendimientos verdad sí hay que darle incentivo subsidio mire lening nosotros tenemos que pagar el impuesto de salida de divisa en educación porque tenemos convenio con universidades en el exterior y lo tienen que pagar muchas empresas en el país entonces Cómo es que usted propone duplicar el salario mínimo sin tomar en cuenta esas otras cosas o quizás las está tomando en cuenta y cómo se explica Porque leni el 80% de la generación de fuentes de trabajo está en las pequeñas y medianas empresas sector privado el sector privado y ellos son los que deben tener incentivo reducción tal vez para el tema de pago de de tributos que les permita en buena medida compensar y reconocerle primero es eso entonces Y luego el incremento salarial que usted propone en en un acto consensuado de participación eh con ambos sectores vamos a decidir es una política que la vamos a implementar pero tiene usted Claro que esos $60 que se pagan de salario básico en el Ecuador son el cuarto salario más alto de América Latina solamente después de Costa Rica Uruguay y chile el problema y usted seguramente lo tiene claro de Ecuador no es eh el el valor del salario es que no hay trabajo que no hay trabajo formal más de 5 millones de personas de los 8 millones y medio de la población económicamente activa están abandonados en la informalidad es decir se ganan la vida sin ningún derecho laboral que es lo que ustedes precisamente defienden Cómo cambiaría eso Lenin varios países han adoptado esto de elevarle un salario o entregarle un salario que le permita vivir más o menos con dignidad Colombia eh pero en Colombia el salario es más bajo que en Ecuador no el estamos hablando que vamos a entregar un salario equivalente a la canasta mínima vital 564 usted me está diciendo que la canasta mínima vital en Colombia es más barata que en Ecuador entonces eh Por supuesto el Ecuador tiene la canasta más cara de América Latina entonces Es evidente que tenemos que compensar en buena medida para el hombre y la mujer que genera la riqueza en el país que son los trabajadores profesor el el el sector privado que es el principal generador de empleo tal como usted lo ha reconocido requiere desde hace tiempo una reforma laboral acorde a los nuevos tiempos a las necesidades de las empresas pero también acorde a las aspiraciones de una juventud a la que no le interesa trabajar 8 horas consecutivas durante 5 días en en una semana tiene usted una propuesta para modernizar este código del trabajo que ya va a cumplir 87 años vamos con Andrés Quispe mi compañero presidente de la une nacional y candidato a asambleísta nacional y llegaremos con un buen bloque de legisladores y vamos a implementar el nuevo código de trabajo creado construido por los trabajadores qué tendrá de nuevo el reconocimiento de nuevas modalidades el reconocimiento y el derecho a la estabilidad parar los abusos que existen los despidos intempestivos y sobre todo garantizarle el un salario digno que estamos hablando que debe ser el equivalente al costo de la canasta mínima V estabilidad laboral si hay personas que quieren tener la posibilidad de trabajar 20 horas a la semana o 30 o o 35 pero ustedes tienen fijada estabilidades 40 horas 5 días a la semana Entonces cómo cómo cómo empatamos eso no nosotros ya hace tiempo 15 de noviembre de 1922 se estableció ya las 8 horas de trabajo la organización Internacional del trabajo reconoce la flexibilización laboral Incluso el trabajo por horas ustedes no mire usted que el pueblo ecuatoriano ya se ratificó en eso la defensa de las 8 horas de trabajo hay modalidades que reconocen la eventualidad en el actual código de trabajo eso ya existe lo que se quiere y se pretendía implementar es retroceder a lo que ya se hizo en la Constituyente yo fui parte del prop del mandato o y por eso yo le pregunto cómo hacer que esta reforma haga que no se retroceda sino que se avance bueno en la medida de que se acojan los las propuestas que están contempladas en esta iniciativa de ley entada por el frente unitario de trabajadores el estado tiene dificultades para cumplir Generalmente mal con sus obligaciones de dar seguridad Salud Educación recursos a los gats vialidad pagar la deuda histórica con la seguridad social el tema de vialidad de energía eléctrica sin contar pues la masa salarial de una burocracia gigantesca hay dificultades presupuestarias usted propone bajar el IVA dejar de pagar la deuda externa con lo que se cerraría una brecha de financi una fuente de financiamiento y yo le quiero preguntar profesor Entonces de dónde saldría el dinero para cubrir con todas estas obligaciones leni no es el estado es quienes han dirigido administrado el estado que ya fracasaron banqueros empresarios como el que tenemos ahora ellos representan el pasado charlatanes que ya dirigieron los destinos del país por eso estamos diciendo ni Correa ni noboa ellos representan el pasado de atraso de corrupción de desesperanza por eso decimos que es la hora del pueblo.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Candidato: Henry Kronfle\n",
      "ID Original: HK1\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "y el domingo debate, el domingo el debate. así es, cómo estás preparándote para esoo. no, yo me siento muy cómodo con el debateporque los confiado. si no hay ética en la política, hermano, Por eso es que la gente está cansada de la pelea de lospolíticos. no entienden, creen que esto es de pelear, de insultar, de meterse. Hero nose entiende la realidad. pero en la asamblea fuiste un puente. Qué vas a hacer si llegas a la presidencia con Jorge glas.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Consulta: ¿Cuáles son sus planes económicos principales?\n",
      "\n",
      "Resultados:\n",
      "\n",
      "Candidato: Wilson Gomez\n",
      "ID Original: WGP005\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "Parte 1: Extracción de petróleo en Ecuador Diagnóstico de la Situación Actual La historia de la extracción de petróleo en Ecuador tiene sus orígenes en la década de 1920, cuando se realizaron los primeros descubrimientos en la región costera. Sin embargo, fue en la década de 1970 cuando el país experimentó su verdadero auge petrolero.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Candidato: Daniel Noboa\n",
      "ID Original: DNP006\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "Un Ecuador conectado, preparado para el futuro, con ciudades resilientes y ecosistemas protegidos Conservación ambiental, adaptación y mitigación al cambio climático Promover la conservación y protección del medio ambiente, la conservación de la biodiversidad y el desarrollo sostenible como pilares fundamentales del desarrollo económico y social del Ecuador, así como la transición hacia una economía verde y con energías renovables.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Candidato: Daniel Noboa\n",
      "ID Original: DNP005\n",
      "Texto original de la entrevista:\n",
      "----------------------------------------\n",
      "Desarrollo económico sostenible para mejorar la calidad de vida de los ecuatorianos Transformación productiva, innovación tecnológica e inversión. Aprobar la Política Nacional para fomento industrial, con el objetivo de Impulsar una transformación productiva hacia la generación cadenas con valor agregado, y la diversificación económica mediante la inversión en infraestructura básica, el fomento de la investigación y desarrollo e innovación.\n",
      "--------------------------------------------------------------------------------\n",
      "Información guardada en 'processed_interviews_info.pkl'\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    test_retrieval(query)\n",
    "\n",
    "# Celda 9: Guardar información para uso futuro\n",
    "import pickle\n",
    "\n",
    "save_data = {\n",
    "    'ids': ids,\n",
    "    'metadata': metadata_list,\n",
    "    'collection_name': collection_name\n",
    "}\n",
    "\n",
    "with open('processed_interviews_info.pkl', 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "print(\"Información guardada en 'processed_interviews_info.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "embedding_model.to(device)\n",
    "\n",
    "qa_model_name = \"mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name).to(device)\n",
    "\n",
    "# Pipeline de QA\n",
    "qa_pipeline = pipeline(\n",
    "    'question-answering',\n",
    "    model=qa_model,\n",
    "    tokenizer=qa_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_response(query, collection, n_results=3):\n",
    "    \"\"\"\n",
    "    Genera una respuesta basada en documentos relevantes.\n",
    "    \n",
    "    Args:\n",
    "        query: str, pregunta del usuario\n",
    "        collection: ChromaDB collection\n",
    "        n_results: int, número de documentos a recuperar\n",
    "    \n",
    "    Returns:\n",
    "        dict: Respuesta generada y metadatos\n",
    "    \"\"\"\n",
    "    # Generar embedding de la consulta\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    \n",
    "    # Recuperar documentos relevantes\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    # Verificar que tenemos resultados\n",
    "    if not results['documents'][0]:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"response\": \"No se encontraron documentos relevantes para esta consulta.\",\n",
    "            \"context_used\": [],\n",
    "            \"metadata\": [],\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    \n",
    "    # Construir el contexto usando el texto original\n",
    "    context_parts = []\n",
    "    for doc, meta in zip(results['documents'][0], results['metadatas'][0]):\n",
    "        # Usar el texto original de la metadata\n",
    "        original_text = meta.get('texto_original', doc)\n",
    "        if original_text:\n",
    "            context_parts.append(f\"Candidato {meta['candidato']}:\\n{original_text}\")\n",
    "    \n",
    "    # Verificar que tenemos contexto\n",
    "    if not context_parts:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"response\": \"No se pudo construir el contexto para la respuesta.\",\n",
    "            \"context_used\": results['documents'][0],\n",
    "            \"metadata\": results['metadatas'][0],\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    \n",
    "    # Procesar el contexto en chunks manejables\n",
    "    max_tokens = 500  # Ajustar según sea necesario\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for part in context_parts:\n",
    "        tokens = qa_tokenizer.encode(part)\n",
    "        if current_length + len(tokens) > max_tokens:\n",
    "            if current_chunk:  # Solo agregar si hay contenido\n",
    "                chunks.append(\"\\n\\n\".join(current_chunk))\n",
    "            current_chunk = [part]\n",
    "            current_length = len(tokens)\n",
    "        else:\n",
    "            current_chunk.append(part)\n",
    "            current_length += len(tokens)\n",
    "    \n",
    "    if current_chunk:  # Agregar el último chunk si existe\n",
    "        chunks.append(\"\\n\\n\".join(current_chunk))\n",
    "    \n",
    "    # Obtener respuestas de cada chunk\n",
    "    answers = []\n",
    "    for chunk in chunks:\n",
    "        if not chunk.strip():  # Verificar que el chunk no esté vacío\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            answer = qa_pipeline(\n",
    "                question=query,\n",
    "                context=chunk,\n",
    "                max_answer_length=200,\n",
    "                handle_impossible_answer=True\n",
    "            )\n",
    "            if answer and answer.get('score', 0) > 0:\n",
    "                answers.append(answer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando chunk: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Seleccionar la mejor respuesta\n",
    "    if answers:\n",
    "        best_answer = max(answers, key=lambda x: x['score'])\n",
    "        confidence = best_answer['score']\n",
    "        \n",
    "        if confidence < 0.1:\n",
    "            response = \"No se encontró una respuesta con suficiente confianza en los documentos analizados.\"\n",
    "        else:\n",
    "            response = best_answer['answer']\n",
    "    else:\n",
    "        response = \"No se pudo generar una respuesta a partir de los documentos disponibles.\"\n",
    "        confidence = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"context_used\": results['documents'][0],\n",
    "        \"metadata\": results['metadatas'][0],\n",
    "        \"confidence\": confidence\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando el sistema RAG actualizado...\n",
      "\n",
      "================================================================================\n",
      "CONSULTA: ¿Qué propuestas tienen sobre seguridad?\n",
      "================================================================================\n",
      "\n",
      "RESPUESTA GENERADA:\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Nivel de confianza: 72.20%\n",
      "\n",
      "FUENTES CONSULTADAS:\n",
      "----------------------------------------\n",
      "\n",
      "[Fuente 1]\n",
      "Candidato: Wilson Gomez\n",
      "ID: WGP005\n",
      "--------------------\n",
      "part extraccion petrole ecuador diagnost situacion actual histori extraccion petrole ecuador origen dec realiz primer descubr region coster embarg dec pais experiment verdader aug petroler construccio...\n",
      "\n",
      "[Fuente 2]\n",
      "Candidato: Luisa Gonzales\n",
      "ID: LG3\n",
      "--------------------\n",
      "quer fern necesit consult ningun asesor manej comun muj capaz inteligent vam ver desafi muestr cuant pais mund viol derech human mantien relacion comercial unid ojal pod dialog pais viol derech human ...\n",
      "\n",
      "[Fuente 3]\n",
      "Candidato: Henry Kronfle\n",
      "ID: HK1\n",
      "--------------------\n",
      "doming debat doming debat asi com preparandot eso sient comod debateporqu confi si etic polit herman gent cans pele lospolit entiend cre pel insult met her nos entiend realid asamble puent vas hac si ...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONSULTA: ¿Cuáles son sus planes económicos principales?\n",
      "================================================================================\n",
      "\n",
      "RESPUESTA GENERADA:\n",
      "----------------------------------------\n",
      "No se encontró una respuesta con suficiente confianza en los documentos analizados.\n",
      "\n",
      "Nivel de confianza: 1.22%\n",
      "\n",
      "FUENTES CONSULTADAS:\n",
      "----------------------------------------\n",
      "\n",
      "[Fuente 1]\n",
      "Candidato: Wilson Gomez\n",
      "ID: WGP005\n",
      "--------------------\n",
      "part extraccion petrole ecuador diagnost situacion actual histori extraccion petrole ecuador origen dec realiz primer descubr region coster embarg dec pais experiment verdader aug petroler construccio...\n",
      "\n",
      "[Fuente 2]\n",
      "Candidato: Daniel Noboa\n",
      "ID: DNP006\n",
      "--------------------\n",
      "ecuador conect prepar futur ciudad resilient ecosistem proteg conserv ambiental adapt mitig cambi climat promov conserv proteccion medi ambient conserv biodivers desarroll sosten pilar fundamental des...\n",
      "\n",
      "[Fuente 3]\n",
      "Candidato: Daniel Noboa\n",
      "ID: DNP005\n",
      "--------------------\n",
      "desarroll econom sosten mejor calid vid ecuatorian transform product innov tecnolog inversion aprob polit nacional foment industrial objet impuls transform product haci gener caden valor agreg diversi...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONSULTA: ¿Qué plantean sobre educación?\n",
      "================================================================================\n",
      "\n",
      "RESPUESTA GENERADA:\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Nivel de confianza: 44.30%\n",
      "\n",
      "FUENTES CONSULTADAS:\n",
      "----------------------------------------\n",
      "\n",
      "[Fuente 1]\n",
      "Candidato: Luisa Gonzales\n",
      "ID: LG3\n",
      "--------------------\n",
      "quer fern necesit consult ningun asesor manej comun muj capaz inteligent vam ver desafi muestr cuant pais mund viol derech human mantien relacion comercial unid ojal pod dialog pais viol derech human ...\n",
      "\n",
      "[Fuente 2]\n",
      "Candidato: Henry Kronfle\n",
      "ID: HK1\n",
      "--------------------\n",
      "doming debat doming debat asi com preparandot eso sient comod debateporqu confi si etic polit herman gent cans pele lospolit entiend cre pel insult met her nos entiend realid asamble puent vas hac si ...\n",
      "\n",
      "[Fuente 3]\n",
      "Candidato: Leonidas Iza\n",
      "ID: LI2\n",
      "--------------------\n",
      "gust compart mañan ingenier leon isa salazarbienven graci atend llam aunqu reves aunqu reves vam sersincer usted quis ven program quer veng pod ven usted andabaocup demor tiemp sal hac presenci medi r...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"¿Qué propuestas tienen sobre seguridad?\",\n",
    "    \"¿Cuáles son sus planes económicos principales?\",\n",
    "    \"¿Qué plantean sobre educación?\",\n",
    "]\n",
    "\n",
    "print(\"\\nProbando el sistema RAG actualizado...\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nConsulta: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = generate_rag_response(query, collection)\n",
    "        \n",
    "        print(\"\\nRespuesta generada:\")\n",
    "        print(result[\"response\"])\n",
    "        print(f\"Nivel de confianza: {result['confidence']:.2%}\")\n",
    "        \n",
    "        if result[\"context_used\"]:\n",
    "            print(\"\\nFuentes utilizadas:\")\n",
    "            for i, (doc, meta) in enumerate(zip(result[\"context_used\"], result[\"metadata\"]), 1):\n",
    "                print(f\"\\nFuente {i}:\")\n",
    "                print(f\"Candidato: {meta['candidato']}\")\n",
    "                print(f\"ID: {meta['id_original']}\")\n",
    "                print(\"-\" * 40)\n",
    "                # Usar el texto original de la metadata si está disponible\n",
    "                display_text = meta.get('texto_original', doc)\n",
    "                print(f\"{display_text[:300]}...\")\n",
    "        else:\n",
    "            print(\"\\nNo se encontraron fuentes relevantes.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la consulta: {str(e)}\")\n",
    "        print(f\"Detalles del error: {type(e).__name__}\")\n",
    "    \n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
